["```js\\1\n\nThe first thing to notice is this contains several layers of asynchronous callback functions. This presents a couple of challenges:\u00a0\u00a0\n\n*   Capturing errors from deep inside a callback\n*   Detecting conditions where the callbacks are never called\n\nThe following is an example of using `assert` for testing. Create a file named\u00a0`test-deleteFile.mjs`\u00a0containing the following:\n\n```", "```js\\1\n\nNo news is good news, meaning it ran without messages and therefore the test passed.\n\nThe `assert` module is used by many of the test frameworks as a core tool for writing test cases. What the test frameworks do is create a familiar test suite and test case structure to encapsulate your test code, plus create a context in which a series of test cases are\u00a0robustly\u00a0executed.\n\nFor example, we asked about the error of the callback function never being called. Test frameworks usually have a timeout so\u00a0that if no result of any kind is\u00a0supplied within a set number of milliseconds, then the test case is considered an error.\n\nThere are many styles of assertion libraries available in Node.js. Later in this chapter, we'll use the Chai assertion library ([http://chaijs.com/](http://chaijs.com/)), which gives you a choice between three different assertion styles (should, expect, and assert).\n\n# Testing a Notes model\n\nLet's start our unit testing journey with the data models we wrote for the Notes application. Because this is unit testing, the models should be tested separately\u00a0from the rest of the Notes application.\n\nIn the case of most of the Notes models, isolating their dependencies implies creating a mock database. Are you going to test the data model or the underlying database? Mocking out a database means creating a fake database implementation,\u00a0which does not look like a productive use of our time. You can argue that testing a data model is really about testing the interaction between your code and the database. Since mocking out the database means not testing that interaction, we should test our code against the database engine in order to validate that interaction.\n\nWith that line of reasoning in mind, we'll skip mocking out the database, and instead run the tests against a database containing test data.\u00a0To simplify launching the test database, we'll use Docker to start and stop a version of the Notes application stack that's set up for testing.\n\nLet's start by setting up the tools.\n\n## Mocha and Chai\u00ad \u2013 the chosen test tools\n\nIf you haven't already done so, duplicate the source tree so that you can use it in this chapter. For example, if you had a directory named `chap12`, create one named `chap13`\u00a0containing everything from `chap12`\u00a0to `chap13`.\n\nIn the `notes` directory, create a new directory named `test`.\n\nMocha ([http://mochajs.org/](http://mochajs.org/)) is one of many test frameworks available for\u00a0Node.js. As you'll see shortly, it helps us write test cases and test suites, and it provides a test results reporting mechanism. It was chosen over the alternatives because it supports Promises. It fits very well with the Chai assertion library mentioned earlier.\u00a0\n\nWhile in the `notes/test` directory, type the following to install Mocha and Chai:\n\n```", "```js\\1\n\nThis loads in the required modules and implements the first test case.\n\nThe Chai library supports three flavors of assertions. We're using the `assert` style here, but it's easy to use a different style if you prefer.\n\nFor the other assertion styles supported by Chai, see [http://chaijs.com/guide/styles/](http://chaijs.com/guide/styles/).\n\nChai's assertions include a very long list of useful assertion functions. For the documentation, see\u00a0[http://chaijs.com/api/assert/](http://chaijs.com/api/assert/).\n\nTo load the model to be tested, we call the `useModel` function (renamed as `useNotesModel`). You'll remember that this uses the `import()` function to dynamically select the actual NotesStore implementation to use. The `NOTES_MODEL` environment variable is used to select which to load.\n\nCalling `this.timeout` adjusts the time allowed for completing the test. By default, Mocha allows 2,000 milliseconds (2 seconds) for a test case to be completed. This particular test case might take longer than that, so we've given it more time.\n\nThe test function is declared as `async`.\u00a0 Mocha can be used in a callback fashion, where Mocha passes in a callback to the test to invoke and indicate errors. However, it can also be used with `async` test functions, meaning that we can throw errors in the normal way and Mocha will automatically capture those errors to determine if the test fails.\n\nGenerally, Mocha looks to see if the function throws an exception or whether the test case takes too long to execute\u00a0(a timeout situation). In either case, Mocha will indicate a test failure. That's, of course, simple to determine for non-asynchronous code. But Node.js is all about asynchronous code, and Mocha has two models for testing asynchronous code. In the first (not seen here), Mocha passes in a callback function, and the test code is to call the callback function. In the second, as seen here, it looks for a Promise being returned by the test function and determines a pass/fail regarding whether the Promise is in the\u00a0`resolve`\u00a0or\u00a0`reject`\u00a0state.\n\nWe are keeping the NotesStore model in the global `store`\u00a0variable so that it can be used by all tests. The test, in this case, is whether we can load a given NotesStore implementation. As the comment states, if this executes without throwing an exception, the test has succeeded.\u00a0 The other purpose of this test is to initialize the variable for use by other test cases.\n\nIt is useful to notice that this code carefully avoids loading `app.mjs`. Instead, it loads the test driver module, `models/notes-store.mjs`, and whatever module is loaded by `useNotesModel`. The\u00a0`NotesStore` implementation is what's being tested, and the spirit of unit testing says to isolate it as much as possible.\n\nBefore we proceed further, let's talk about how Mocha structures tests.\n\nWith Mocha, a test suite is contained within a `describe` block. The first argument is a piece of descriptive text that you use to tailor the presentation of test results. The second argument is a `function` that contains the contents of the given test suite.\n\nThe `it` function is a test case. The intent is for us to read this as\u00a0*it should successfully load the module*. Then, the code within the `function` is used to check that assertion.\n\nWith Mocha, it is important to not use arrow functions in the\u00a0`describe`\u00a0and\u00a0`it`\u00a0blocks. By now, you will have grown fond of arrow functions because of how much easier they are to write. However, Mocha calls these functions with\u00a0a\u00a0`this`\u00a0object containing useful functions for Mocha. Because arrow functions avoid setting up\u00a0a\u00a0`this`\u00a0object, Mocha would break.\n\nNow that we have a test case written, let's learn how to run tests.\n\n### Running the first test case\n\nNow that we have a test case, let's run the test. In the `package.json`\u00a0file, add the following\u00a0`scripts` section:\n\n```", "```js\\1\n\nThis runs a series of steps one after another, relying on a feature of the Bash shell. The `npm-run-all` tool serves the same purpose, namely running one `package.json` script after another in the series. The first advantage is that the code is simpler and more compact, making it easier to read, while the other advantage is that it is cross-platform. We're using `cross-env` for the same purpose so that the test scripts can be executed on Windows as easily as they can be on Linux or macOS.\n\nFor the `test-notes-sequelize-sqlite` test, look closely. Here, you can see that we need a database configuration file named `sequelize-sqlite.yaml`. Create that file with the following code:\n\n```", "```js\\1\n\nIf all has gone well, you'll get this result for every test combination currently supported in the `test-all` script.\n\nThis completes the first test, which was to demonstrate how to create tests and execute them. All that remains is to write more tests.\n\n### Adding some tests\n\nThat was easy, but if we want to find what bugs we created, we need to test some functionality. Now, let's create a test suite for testing `NotesStore`, which will contain several test suites for different aspects of `NotesStore`.\n\nWhat does that mean? Remember that the `describe` function is the container for a test suite and that the `it` function is the container for a test case. By simply nesting `describe` functions, we can contain a test suite within a test suite. It will be clearer what that means after we implement this:\n\n```", "```js\\1\n\nAs suggested by the description for this test suite, the functions all test the `keylist` method.\n\nFor each test case, we start by calling `keylist`, then using `assert` methods to check different aspects of the array that is returned. The idea is to call `NotesStore` API functions, then test the results to check whether they matched the expected results.\n\nNow, we can run the tests and get the following:\n\n```", "```js\\1\n\nThese tests check the `read` method. In the first test case, we check whether it successfully reads a known Note, while in the second test case, we have a negative test of what happens if we read a non-existent Note.\n\nNegative tests are very important to ensure that functions fail when they're supposed to fail and that failures are indicated correctly.\n\nThe Chai Assertions API includes some very expressive assertions. In this case, we've used the\u00a0`deepEqual`\u00a0method, which does a deep comparison of two objects. You'll see that for the first argument, we pass in an object and that for the second, we pass an object that's used to check the first. To see why this is useful, let's force it to indicate an error by inserting `FAIL` into one of the test strings.\n\nAfter running the tests, we get the following output:\n\n```", "```js\\1\n\nOur test suite found two errors, one of which is the error we mentioned in [Chapter 7](ae8529e5-3a08-45cc-89e9-82895eb45641.xhtml),\u00a0*Data Storage and Retrieval*. Both failures came from the negative test cases. In one case, the test calls `store.read(\"badkey12\")`, while in the other, it calls `store.delete(\"badkey12\")`.\n\nIt is easy enough to insert\u00a0`console.log`\u00a0calls and learn what is going on.\n\nFor the `read` method, SQLite3 gave us\u00a0`undefined`\u00a0for\u00a0`row`. The test suite successfully calls the\u00a0`read`\u00a0function multiple times with a\u00a0`notekey`\u00a0value that does exist. Obviously, the failure is limited to the case of an invalid\u00a0`notekey`\u00a0value. In such cases, the query gives an empty result set and SQLite3 invokes the callback with\u00a0`undefined`\u00a0in both the\u00a0error and the\u00a0row values. Indeed, the equivalent `SQL SELECT` statement does not throw an error; it simply returns an empty result set. An empty result set isn't an error, so we received no error and an undefined\u00a0`row`.\n\nHowever, we defined `read` to throw an error if no such Note exists. This means this function must be written to detect this condition and throw an error.\n\nThere is a difference between the `read` functions in\u00a0`models/notes-sqlite3.mjs` and\u00a0`models/notes-sequelize.mjs`. On the day we wrote `SequelizeNotesStore`, we must have thought through this function more carefully than we did on the day we wrote `SQLITE3NotesStore`. In\u00a0`SequelizeNotesStore.read`, there is\u00a0an error that's thrown when we receive an empty result set,\u00a0and it has a check that we can adapt. Let's rewrite the\u00a0`read`\u00a0function in\u00a0`models/notes-sqlite.mjs`\u00a0so that it reads as follows:\n\n```", "```js\\1\n\nUnfortunately, there isn't a method in the SQL option to fail if it does not delete any records. Therefore, we must add a check to see if a record exists, namely the following:\n\n```", "```js\\1\n\nThis is the same change; that is, to first `read` the Note corresponding to the given `key`, and if the Note does not exist, to throw an error.\n\nLikewise, when running `test-level`, we get a similar failure, and the solution is to edit `models/notes-level.mjs` to make the following change:\n\n```", "```js\\1\n\nThis would deploy a second VPC with a different name that's explicitly for test execution and that would not disturb the production deployment. It's quite common in Terraform to customize the deployment this way for different targets.\n\nIn this section, we'll try something different. We can use Docker Swarm in other contexts, not just the AWS EC2 infrastructure we set up. Specifically, it is easy to use Docker Swarm with the Docker for Windows or Docker for macOS that's running on our laptop.\n\nWhat we'll do is configure Docker on our laptop so that it supports swarm mode and create a slightly modified version of the Stack file in order to run the tests on our laptop. This will solve the issue of running tests against a MySQL database server, and also lets us test the long-neglected MongoDB module. This will demonstrate how to use Docker Swarm for test infrastructure and how to perform semi-automated test execution inside the containers using a shell script.\n\nLet's get started.\n\n## Using Docker Swarm to deploy test infrastructure\n\nWe had a great experience using Docker Compose and Swarm to orchestrate Notes application deployment on both our laptop and our AWS infrastructure. The whole system, with five independent services,\u00a0is easily described in `compose-local/docker-compose.yml`\u00a0and `compose-swarm/docker-compose.yml`. What we'll do is duplicate\u00a0the Stack file, then make a couple of small changes required to support test execution in a local swarm.\n\nTo configure the Docker installation on our laptop for swarm mode, simply type the following:\n\n```", "```js\\1\n\nNormally, this is used for a host that you wish to detach from an existing swarm. If there is only one host remaining in a swarm, the effect will be to shut down the swarm.\n\nNow that we know how to initialize swarm mode on our laptop, let's set about creating a stack file suitable for use on our laptop.\n\nCreate a new directory, `compose-stack-test-local`, as a sibling to the `notes`, `users`, and `compose-local` directories. Copy `compose-stack/docker-compose.yml` to that\u00a0directory. We'll be making several small changes to this file and no changes to the existing Dockerfiles. As much as it is possible, it is important to test the same containers that are used in the production deployment. This means it's acceptable to inject test files into the containers, but not modify them.\n\nMake every `deploy` tag look like this:\n\n```", "```js\\1\n\nThis injects the files required for testing into the `svc-notes` container. Obviously, this is the `test` directory that we created in the previous section for the Notes service. Those tests also require the SQLite3 schema file since it is used by the corresponding test script. In both cases, we can use `bind` mounts to inject the files into the running container.\n\nThe Notes test suite follows a normal practice for Node.js projects of putting `test` files in the test directory. When building the container, we obviously don't include the test files because they're not required for deployment. But running tests requires having that directory inside the running container. Fortunately, Docker makes this easy. We simply mount the directory into the correct place.\n\nThe bottom line is this approach gives us the following advantages:\n\n*   The test code is in\u00a0`notes/test`,\u00a0where it belongs.\n*   The test code is not copied into the production container.\n*   In test mode, the\u00a0`test`\u00a0directory appears where it belongs.\n\nFor Docker (using `docker run`) and Docker Compose, the volume is mounted from a directory on the localhost. But for swarm mode, with a multi-node swarm, the container could be deployed on any host matching the placement constraints we declare. In a swarm, bind volume mounts like the ones shown here will try to mount from a directory on the host that the container has been deployed in. But we are not using a multi-node swarm; instead, we are using a single-node swarm. Therefore, the container will mount the named directory from our laptop, and all will be fine. But as soon as we decide to run testing on a multi-node swarm, we'll need to come up with a different strategy for injecting these files into the container.\n\nWe've also changed the `ports` mappings. For `svc-userauth`, we've made its port visible to give ourselves the option of testing the REST service from the host computer. For the `svc-notes` service, this will make it appear on port `3000`. In the `environment` section, make sure you did not set a `PORT` variable. Finally, we adjust `TWITTER_CALLBACK_HOST`\u00a0so that it uses\u00a0`localhost:3000` since we're deploying on the localhost.\n\nFor both services, we're changing the image tag from the one associated with the AWS ECR repository to one of our own designs. We won't be publishing these images to an image repository, so we can use any image tag we like.\u00a0\u00a0\n\nFor both services, we are using the Sequelize data model, using the existing MySQL-oriented configuration file, and setting the `SEQUELIZE_DBHOST` variable to refer to the container holding the database.\u00a0\n\nWe've defined a Docker Stack file that should be useful for deploying the Notes application stack in a Swarm. The difference between the deployment on AWS EC2 and here is simply the configuration. With a few simple configuration changes, we've mounted test files into the appropriate container, reconfigured the volumes and the environment variables, and changed the deployment descriptors so that they're suitable for a single-node swarm running on our laptop.\n\nLet's deploy this and see how well we did.\n\n## Executing tests under Docker Swarm\n\nWe've repurposed our Docker Stack file so that it describes deploying to a single-node swarm, ensuring the containers are set up to be useful for testing. Our next step is to deploy the Stack to a swarm and execute\u00a0the tests inside the Notes container.\n\nTo set it up, run the following commands:\n\n```", "```js\\1\n\nBecause a Stack file is also a Compose file, we can run `docker-compose build` to build the images. Because of the `image` tags, this will automatically tag the images so that they match the image names we specified.\n\nThen, we use `docker stack deploy`, as we did when deploying to AWS EC2\\. Unlike the AWS deployment, we do not need to push the images to repositories, which means we do not need to use the `--with-registry-auth` option. This will behave almost identically to the swarm we deployed to EC2, so we explore the deployed services in the same way:\n\n```", "```js\\1\n\nBecause, in swarm mode, the containers have unique names, we have to run `docker ps` to get the container name, then paste it into this command to start a Bash shell inside the container.\n\nInside the container, we see the `test` directory is there as expected. But we have a couple of setup steps to perform. The first is to install the SQLite3 command-line tools since the scripts in `package.json` use that command. The second is to remove any existing `node_modules` directory because we don't know if it was built for this container or for the laptop. After that, we need to run\u00a0`npm install` to install the dependencies.\n\nHaving done this,\u00a0we can run the tests:\n\n```", "```js\\1\n\nThis is the command that's required to execute the test suite against the MySQL database.\n\nThen, we can run the tests against MySQL, like so:\n\n```", "```js\\1\n\nThe script executes each script in `notes/test/package.json` individually. If you prefer, you can replace these with a single line that executes `npm run test-all`.\n\nThis script takes a command-line argument for the container name holding the `svc-notes` service. Since the tests are located in that container, that's where the tests must be run. The script can be executed like so:\n\n```", "```js\\1\n\nThat's all that's required to add a MongoDB container to a Docker Compose/Stack file. We've connected it to `frontnet` so that the database is accessible by `svc-notes`. If we wanted the `svc-notes`\u00a0container to use MongoDB, we'd need some environment variables (`MONGO_URL`, `MONGO_DBNAME`, and `NOTES_MODEL`) to tell Notes to use MongoDB.\u00a0\n\nBut we'd also run into a problem that we created for ourselves in [Chapter 9](3d687da9-7857-4c79-915b-b5b79873748c.xhtml), *Dynamic Client/Server Interaction with Socket.IO*. In that chapter, we created a messaging subsystem so that our users can leave messages for each other. That messaging system is currently implemented to store messages in the same Sequelize database where the Notes are stored. But to run Notes with no Sequelize database would mean a failure in the messaging system. Obviously, the messaging system can be rewritten, for instance, to allow storage in a MongoDB database, or to support running both MongoDB and Sequelize at the same time.\n\nBecause we were careful, we can execute code in `models/notes-mongodb.mjs` without it being affected by other code. With that in mind, we'll simply execute the Notes test suite against MongoDB and report the results.\n\nThen, in `notes/test/package.json`, we can add a line to facilitate running tests on MongoDB:\n\n```", "```js\\1\n\nThis ensures MongoDB can be tested alongside the other test combinations. But when we run this, an error might crop up:\n\n```", "```js\\1\n\nThis adds a pair of useful configuration options, including the option explicitly named in the error message. Otherwise, the code is unchanged.\n\nTo make sure the container is running with the updated code, rerun the `docker-compose build` and `docker stack deploy` steps shown earlier. Doing so rebuilds the images, and then updates the services. Because the `svc-notes` container will relaunch, you'll need to install the Ubuntu\u00a0`sqlite3` package again.\n\nOnce you've done that, the tests will all execute correctly, including the MongoDB combination.\n\nWe can now report the final test results matrix to the manager:\n\n*   `models-fs`: PASS\n*   `models-memory`: PASS\n*   `models-levelup`: 1 failure, now fixed, PASS\n*   `models-sqlite3`: Two failures, now fixed, PASS\n*   `models-sequelize`\u00a0with SQLite3: 1 failure, now fixed, PASS\n*   `models-sequelize`\u00a0with MySQL: PASS\n*   `models-mongodb`: PASS\n\nThe manager will tell you \"good job\" and then remember that the models are only a portion of the Notes application. We've left two areas completely untested:\n\n*   The REST API for the user authentication service\n*   Functional testing of the user interface\n\nIn this section, we've learned how to repurpose a Docker Stack file so that we can launch the Notes stack on our laptop. It took a few simple reconfigurations of the Stack file and we were ready to go, and we even injected the files that are useful for testing. With a little bit more work, we finished testing against all configuration combinations of the Notes database modules.\n\nOur next task is to handle testing the REST API for the user authentication service.\n\n# Testing REST backend services\n\nIt's now time to turn our attention to the user authentication service. We've mentioned testing this service, saying that we'll get to them later. We developed a command-line tool for both administration and ad hoc testing. While that has been useful all along, it's time to get cracking with some real tests.\n\nThere's a question of which tool to use for testing the authentication service. Mocha does a good job of organizing a series of test cases, and we should reuse it here. But the thing we have to test is a REST service.\u00a0The customer of this service, the Notes application, uses it through the REST API, giving us a perfect rationalization to test the REST interface rather than calling the functions directly.\u00a0Our ad hoc scripts used the SuperAgent library to simplify making REST API calls. There happens to be a companion library, SuperTest, that is meant for REST API testing. It's easy to use that library within a Mocha test suite, so let's take that route.\n\nFor the documentation\u00a0on SuperTest, look here:\u00a0[https://www.npmjs.com/package/supertest](https://www.npmjs.com/package/supertest).\n\nCreate a directory named `compose-stack-test-local/userauth`. This directory will contain a test suite for the user authentication REST service. In that directory, create a file named `test.mjs`\u00a0that contains the following code:\n\n```", "```js\\1\n\nThese are our `before` and `after` tests. We'll use them to establish a user and then clean them up by removing the user at the end.\n\nThis gives us a taste of how the `SuperTest` API works. If you refer back to `cli.mjs`, you'll see the similarities to `SuperAgent`.\n\nThe `post` and `delete` methods we can see here declare the HTTP verb to use. The `send` method provides an object for the `POST` operation. The `set` method sets header values, while\u00a0the `auth` method sets up authentication:\n\n```", "```js\\1\n\nWe are checking the `/find` operation in two ways:\n\n*   **Positive test**: Looking for the account we know exists \u2013 failure is indicated if the user account is not found\n*   **Negative test**: Looking for the one we know does not exist \u2013 failure is indicated if we receive something other than an error or an empty object\n\nAdd the following test case:\n\n```", "```js\\1\n\nThis injects the\u00a0`userauth` directory into the container as the `/userauth/test` directory. As we did previously, we then must get into the container and run the test script.\n\nThe next step is creating a `package.json`\u00a0file to hold any dependencies and a script to run the test:\n\n```", "```js\\1\n\nThis adds a second argument\u00a0\u2013 in this case, the container name for `svc-userauth`. We can then run the test suite, using this script to run them inside the container. The first two commands ensure the installed packages were installed for the operating system in this container, while the last runs the test suite.\n\nNow, if you run the `run.sh` test script, you'll see the required packages get installed. Then, the test suite will be executed.\n\nThe result will look like this:\n\n```", "```js\\1\n\nThen, you can use a specific Reporter, like so:\n\n```", "```js\\1\n\nFor Mocha, the `--reporter` option selects which Reporter to use. In this case, we selected the TAP reporter, and the output follows that format.\n\n**Test Anything Protocol** (**TAP**)\u00a0is a widely used test results format\u00a0that\u00a0increases the possibility of finding higher-level reporting tools. Obviously, the next step would be to save the results into a file somewhere, after mounting a host directory into the container.\n\nIn this section, we learned about the test results reporting formats supported by Mocha. This will give you a starting point for collecting long-term results tracking and other useful software quality metrics. Often, software teams rely on quality metrics trends as part of deciding whether a product can be shipped to the public.\n\nIn the next section, we'll round off our tour of testing methodologies by learning about a framework for frontend testing.\n\n# Frontend headless browser testing\u00a0with Puppeteer\n\nA big cost area in testing is manual\u00a0user interface\u00a0testing. Therefore, a wide range of tools has been developed to automate running tests at the HTTP level. Selenium is a popular tool implemented in Java, for example. In the Node.js world, we have a few interesting choices. The *chai-http* plugin to Chai would let us interact at the HTTP level with the Notes application while staying within the now-familiar Chai environment.\u00a0\n\nHowever, in this section, we'll use Puppeteer ([https://github.com/GoogleChrome/puppeteer](https://github.com/GoogleChrome/puppeteer)). This tool is a high-level Node.js module used to control a headless Chrome or Chromium browser, using the DevTools protocol. This protocol allows\u00a0tools to instrument, inspect, debug, and profile Chromium or Chrome browser instances. The key result is that we can test the Notes application in a real browser so that we have greater assurance it behaves correctly for users.\u00a0\n\nThe Puppeteer website has extensive documentation that's worth reading:\u00a0[https://pptr.dev/](https://pptr.dev/).\n\nPuppeteer is meant to be a general-purpose test automation tool and has a strong feature set for that purpose. Because it's easy to make web page screenshots with Puppeteer, it can also be used in a screenshot service.\n\nBecause Puppeteer is controlling a real web browser, your user interface tests will be very close to live browser testing, without having to hire a human to do the work. Because it uses a headless version of Chrome, no visible browser window will show on your screen, and tests can be run in the background instead. It can also drive other browsers by using the DevTools protocol.\n\nFirst, let's set up a directory to work in.\n\n## Setting up a Puppeteer-based testing project directory\n\nFirst, let's set up the directory that\u00a0we'll install Puppeteer in, as well as the other packages that will be required for this project:\n\n```", "```js\\1\n\nThe Puppeteer package will launch that Chromium instance as needed, managing it as a background process and communicating with it using the DevTools protocol.\n\nThe approach we'll follow is to test against the Notes stack we've deployed in the test Docker infrastructure. Therefore, we need to launch that infrastructure:\n\n```", "```js\\1\n\nThis imports\u00a0and configures\u00a0the required modules. This includes setting up `bcrypt` support in the same way that is used in the authentication server. We've also copied in the authentication key for the user authentication backend service. As we did for the REST test suite, we will use the `SuperTest` library to add, verify, and remove the test user using the REST API snippets copied from the REST tests.\n\nAdd the following test block:\n\n```", "```js\\1\n\nAt the end of the test execution, we should run this to delete the test user. The policy is to clean up after we execute the test. Again, this was copied from the user authentication service test suite. Between those two, add the following:\n\n```", "```js\\1\n\nThe test infrastructure we deployed earlier exposes the user authentication service on port `5858`\u00a0and the Notes application on port `3000`. If you want to test against a different deployment, adjust these URLs appropriately. Before running this, the Docker test infrastructure must be launched, which should have already happened.\n\nLet's try running this initial test suite:\n\n```", "```js\\1\n\nThis is our test implementation for logging in and out. We have to specify the `timeout` value because it is a new `describe` block.\n\nThe `click` method takes a CSS selector, meaning this first click event is sent to the Login button. A CSS selector, as the name implies, is similar to or identical to the selectors we'd write in a CSS file. With a CSS selector, we can target specific elements on the page.\n\nTo determine the selector to use, look at the HTML for the templates and learn how to describe the element you wish to target. It may be necessary to add ID attributes into the HTML to improve testability.\n\nThe Puppeteer documentation refers to the CSS Selectors documentation on the Mozilla Developer Network website:\u00a0[https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors).\n\nClicking on the Login button will, of course, cause the Login page to appear. To verify this, we wait until the page contains a form that posts to `/users/login`. That form is in `login.hbs`.\n\nThe `type` method acts as a user typing text. In this case, the selectors target the `Username` and `Password` fields of the login form. The `delay` option inserts a pause of 100 milliseconds after typing each character. It was noted in testing that sometimes, the text arrived with missing letters, indicating that Puppeteer can type faster than the browser can accept.\n\nThe `page.keyboard` object has various methods related to keyboard events. In this case, we're asking to generate the equivalent to pressing *Enter* on the keyboard. Since, at that point, the focus is in the Login form, that will cause the form to be submitted to the Notes application. Alternatively, there is a button on that form, and the test could instead click on the button.\n\nThe `waitForNavigation` method has a number of options for waiting on page refreshes to finish. The selected option causes a wait until the DOM content of the new page is loaded.\n\nThe `$` method searches the DOM for elements matching the selector, returning an array of matching elements. If no elements match, `null` is returned instead. Therefore, this is a way to test whether the application got logged in, by looking to see if the page has a Logout button.\n\nTo log out, we click on the Logout button. Then, to verify the application logged out, we wait for the page to refresh and show a Login button:\n\n```", "```js\\1\n\nThis is the same code as the code for the body of the test cases shown previously, but we've moved the code to their own functions. With this change, any test case that wishes to log into the test user can use these functions.\n\nThen, we need to change the login/logout tests to this:\n\n```", "```js\\1\n\nThese are our test cases for adding and deleting Notes. We start with the `doLogin` and `checkLogin` functions to ensure the browser is logged in.\n\nAfter clicking on the\u00a0Add Note button and waiting for the browser to show the form in which we enter the Note details, we need to enter text into the form fields. The `page.type` method acts as a user typing on a keyboard and types the given text into the field identified by the selector.\n\nThe interesting part comes when we verify the note being shown. After clicking the **Submit** button, the browser is, of course, taken to the page to view the newly created Note. To do this, we use `page.$eval` to retrieve text from certain elements on the screen.\n\nThe `page.$eval` method scans the page for matching elements, and for each, it calls the supplied callback function. The callback function is given the element, and in our case, we call the `textContent` method to retrieve the textual form of the element. Then, we're able to use the `assert.include`\u00a0function to test that the element contains the required text.\n\nThe `page.url()` method, as its name suggests, returns the URL currently being viewed. We can test whether that URL contains `/notes/view` to be certain the browser is viewing a note.\n\nTo delete the note, we start by verifying that the **Delete** button is on the screen. Of course, this button is there if the user is logged in. Once the button is verified, we click on it and wait for the `FORM` that confirms that we want to delete the Note. Once it shows up, we can click on the button, after which we are supposed to land on the home page.\n\nNotice that to find the Delete button, we need to refer to `a#notedestroy`. As it stands, the template in question does not have that ID anywhere. Because the HTML for the Delete button was not set up so that we could easily create a CSS selector, we must edit `views/noteedit.hbs` to change the Delete button to this:\n\n```", "```js\\1\n\nWe have more passing tests and have made good progress. Notice how one of the test cases took 18 seconds to finish. That's partly because we slowed text entry down to make sure it is correctly received in the browser, and there is a fair amount of text to enter. There was a reason we increased the timeout.\n\nIn earlier tests, we had success with negative tests, so let's see if we can find any bugs that way.\n\n## Implementing negative tests with Puppeteer\n\nRemember that a negative test is used to purposely invoke scenarios that will fail. The idea is to ensure the application fails correctly, in the expected manner.\n\nWe have two scenarios for an easy negative test:\n\n*   Attempt to log in using a bad user ID and password\n*   Access a bad URL\n\nBoth of these are easy to implement, so let's see how it works.\n\n### Testing login with a bad user ID\n\nA simple way to ensure we have a bad username and password is to generate random text strings for both. An easy way to do that is with the `uuid` package. This package is about generating Universal Unique IDs (that is, UUIDs), and one of the modes of using the package simply generates a unique random string. That's all we need for this test; it is a guarantee that the string will be unique.\n\nTo make this crystal clear, by using a unique random string, we ensure that we don't accidentally use a username that might be in the database. Therefore, we will be certain of supplying an unknown username when trying to log in.\n\nIn `uitest.mjs`, add the following to the imports:\n\n```", "```js\\1\n\nThis starts with the login scenario. Instead of a fixed username and password, we instead use the results of calling `uuidv4()`, or the random UUID string.\n\nThis does the login action, and then we wait for the resulting page. In trying this manually, we learn that it simply returns us to the login screen and that there is no additional message. Therefore, the test looks for the login form and ensures there is a Login button. Between the two, we are certain the user is not logged in.\n\nWe did not find a code error with this test, but there is a user experience error: namely, the fact that, for a failed login attempt, we simply show the login form and do not provide a message (that is, *unknown username or password*), which leads to a bad user experience. The user is left feeling confused over what just happened. So, let's put that on our backlog to fix.\n\n### Testing a response to a bad URL\u00a0\n\nOur next negative test is to try a bad URL in Notes. We coded Notes to return a 404 status code, which means the page or resource was not found. The test is to ask the browser to visit the bad URL, then verify that the result uses the correct error message.\n\nAdd the following test case:\n\n```"]