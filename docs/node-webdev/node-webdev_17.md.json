["```js\\1\n\nBecause the `svc-notes` container will not be handling inbound traffic, we start by disabling its `ports` tag. This has the effect of ensuring it does not export any ports to the public. Instead, notice that in the `cronginx` container we export both port `80` (HTTP) and port `443` (HTTPS). That container will take over interfacing with the public internet.\n\nAnother change on `svc-notes` is to set the `TWITTER_CALLBACK_HOST`\u00a0environment variable. Set this to the domain name you've chosen. Remember that correctly setting this variable is required for successful login using Twitter. Until we finish implementing HTTPS, this should have an HTTP URL.\n\nThe `deploy` tag for Cronginx is the same as for `svc-notes`. In theory, because `svc-notes` is no longer interacting with the public it could be redeployed to an EC2 instance on the private network. Because both are attached to `frontnet`, either will be able to access the other with a simple domain name reference, which we'll see in the configuration file.\n\nThis container uses the same DNS configuration, because Certbot needs to be able to reach the Let's Encrypt servers to do its work.\n\nThe final item of interest is the volume mounts. In the previous section, we discussed certain directories that must be mounted into this container. As with the database containers, the purpose is to persist the data in those directories while letting us destroy and recreate the Cronginx container as needed. Each directory is mounted from `/home/ubuntu` because that's the directory that is available on the EC2 instances. The three directories are as follows:\n\n*   `/etc/letsencrypt`: As discussed earlier, Certbot uses this directory to track administrative information about domains being managed on the server. It also stores the SSL certificates in this directory.\n*   `/webroots`: This directory will be used in satisfying the HTTP-01 request to the\u00a0`http://<YOUR_DOMAIN>/.well-known/acme-challenge/<TOKEN>` URL.\n*   `/etc/nginx/conf.d`: This directory holds the NGINX configuration files for each domain we'll handle using this Cronginx instance.\n\nFor NGINX configuration, there is a default config file at `/etc/nginx/nginx.conf`. That file automatically includes any configuration file in\u00a0`/etc/nginx/conf.d`, within an `http` context. What that means is each such file should have one or more `server` declarations. It won't be necessary to go deeper into learning about NGINX since the config files we will use are very straightforward.\n\nWe will be examining NGINX configuration files. If you need to learn more about these files, the primary documentation is at\u00a0[https://nginx.org/en/docs/](https://nginx.org/en/docs/).\n\nFurther documentation for the commercial NGINX Plus product is at\u00a0[https://www.nginx.com/resources/admin-guide/](https://www.nginx.com/resources/admin-guide/).\n\nThe NXING website has a *Getting Started* section with many useful recipes at\u00a0[https://www.nginx.com/resources/wiki/start/](https://www.nginx.com/resources/wiki/start/).\n\nIt will be a useful convention to follow to have one file in the\u00a0`/etc/nginx/conf.d` directory for each domain you are hosting. That means, in this project, you will have one domain, and therefore you'll store one file in the directory named `YOUR-DOMAIN.conf`. For the example domain we configured earlier, that file would be `notes.geekwisdom.net.conf`.\n\n### Creating an NGINX configuration to support registering domains with Let's Encrypt\n\nAt this point, you have selected a domain you will use for Notes. To register a domain with Let's Encrypt, we need a web server configured to satisfy requests to\u00a0the\u00a0`http://<YOUR_DOMAIN>/.well-known/acme-challenge/<TOKEN>`\u00a0URL, and where the corresponding directory is writable by Certbot. All the necessary elements are contained in the Cronginx container.\u00a0\n\nWhat we need to do is create an NGINX configuration file suitable for handling registration, then run the shell script supplied inside Cronginx. After registration is handled, there will be another NGINX configuration file that's suitable for HTTPS. We'll go over that in a later section.\n\nCreate a file for your domain named `initial-YOUR-DOMAIN.conf`, named this way because it's the initial configuration file for the domain. It will contain this:\n\n```", "```js\\1\n\nThere is an existing shell script that performs the Docker setup. These three lines are appended to that script and create the directories.\n\nWith this in place, we can redeploy the EC2 cluster, and the directories will be there ready to be used.\n\n### Deploying the EC2 cluster and Docker swarm\n\nAssuming that the EC2 cluster is currently not deployed, we can set it up as we did in [Chapter 12](8551a26c-6834-4df6-b392-60a15c20f6ff.xhtml),\u00a0*Deploying a Docker Swarm to AWS EC2 with Terraform*. In `terraform-swarm`, run this command:\n\n```", "```js\\1\n\nThe\u00a0`chown`\u00a0command is required because when Terraform created that directory it became owned by the\u00a0`root`\u00a0user. It needs to be owned by the\u00a0`ubuntu`\u00a0user for the\u00a0`scp`\u00a0command to work.\n\nAt this point make sure that, in `compose-swarm/docker-compose.yml`, the\u00a0`TWITTER_CALLBACK_HOST`\u00a0environment variable\u00a0for `svc-notes` is set to the HTTP URL (`http://YOUR-DOMAIN`) rather than the HTTPS URL. Obviously you have not yet provisioned HTTPS and can only use the HTTP domain.\n\nWith those things set up, we can run this:\n\n```", "```js\\1\n\nYou see there is a file named\u00a0`register.sh`\u00a0containing the following:\n\n```", "```js\\1\n\nWe run the shell script using\u00a0`sh -x register.sh`\u00a0and supply our chosen domain name as the first argument. Notice that it creates the\u00a0`/webroots`\u00a0directory, which is required for the Let's Encrypt validation. It then runs\u00a0`certbot certonly`, and the tool starts asking questions required for registering with the service.\n\nThe registration process ends with this message:\n\n```", "```js\\1\n\nThis reconfigures the HTTP server to do permanent redirects to the HTTPS site. When an HTTP request results in a 301 status code, that is a permanent redirect. Any redirect tells web browsers to visit a URL provided in the redirect. There are two kinds of redirects, temporary and permanent, and the 301 code makes this a permanent redirect. For permanent redirects, the browser is supposed to remember the redirect and apply it in the future. In this case, the redirect URL is computed to be the request URL, rewritten to use the HTTPS protocol.\n\nTherefore our users will silently be sent to the HTTPS version of Notes, with no further effort on our part.\n\nTo implement the HTTPS server, add this to the config file:\n\n```", "```js\\1\n\nThe next question is how do we restart the NGINX server so it reads the new configuration file? One way is to send a SIGHUP signal to the NGINX process, causing it to reload the configuration:\n\n```", "```js\\1\n\nThat will kill the existing container and start a new one.\n\nInstead of that rosy success message, you might get this instead:\n\n```", "```js\\1\n\nThe\u00a0`-a`\u00a0option causes\u00a0`docker ps`\u00a0to return information about every container, even the ones that are\u00a0not\u00a0currently running. With the container name in hand, we can run this:\n\n```", "```js\\1\n\nAs before, we run `docker ps` to find out the exact container name. With that name, we start a command shell inside the container. The actual act is simple, we just run `certbot delete` and specify the domain name.\n\nCertbot doesn't just go ahead and delete the registration. Instead, it asks you to verify that's what you want to do, then it deletes the registration.\n\nIn this section, we have finished implementing HTTPS support for Notes by learning how to test that it is implemented correctly.\n\nWe've accomplished a redesign of the Notes application stack using a custom NGINX-based container to implement HTTPS support. This approach can be used for any service deployment, where an NGINX instance is used as the frontend to any kind of backend service.\n\nBut we have other security fish to fry. Using HTTPS solves only part of the security problem. In the next section, we'll look at Helmet, a tool for Express applications to set many security options in the HTTP headers.\n\n# Using Helmet for across-the-board security in Express applications\n\nWhile it was useful to implement HTTPS, that's not the end of implementing security measures. It's hardly the beginning of security, for that matter. The browser makers working with the standards organizations have defined several mechanisms for telling the browser what security measures to take. In this section, we will go over some of those mechanisms, and how to implement them using Helmet.\n\nHelmet ([https://www.npmjs.com/package/helmet](https://www.npmjs.com/package/helmet)) is, as the development team says, not a security silver bullet (do Helmet's authors think we're trying to protect against vampires?). Instead, it is a toolkit for setting various security headers and taking other protective measures in Node.js applications. It integrates with several packages that can be either used independently or through Helmet.\n\nUsing Helmet is largely a matter of importing the library into `node_modules`, making a few configuration settings, and integrating it with Express.\n\nIn the `notes` directory, install the package like so:\n\n```", "```js\\1\n\nThat's enough for most applications. Using Helmet out of the box provides a reasonable set of default security options. We could be done with this section right now, except that it's useful to examine closely what Helmet does, and its options.\n\nHelmet is actually a cluster of 12 modules for applying several security techniques. Each can be individually enabled or disabled, and many have configuration settings to make. One option is instead of using that last line, to initialize and configure the sub-modules individually. That's what we'll do in the following sections.\n\n## Using Helmet to set the Content-Security-Policy header\n\nThe **Content-Security-Policy** (**CSP**) header can help to protect against injected malicious JavaScript and other file types.\n\nWe would be remiss to not point out a glaring problem with services such as the Notes application. Our users could enter any code they like, and an improperly behaving application will simply display that code. Such applications can be a vector for JavaScript injection attacks among other things.\n\nTo try this out, edit a note and enter something like this:\n\n```", "```js\\1\n\nIn Handlebars, a value appearing in a template using two curly braces (`{{encoded}}`) is encoded using HTML coding. For the previous example, the angle bracket is encoded as\u00a0`&lt;` and so on for display, rendering that JavaScript code as neutral text rather than as HTML elements. If instead, you use three curly braces (`{{{notEncoded}}}`), the value is not encoded and is instead presented as is. The malicious JavaScript would be executed in your visitor's browser, causing problems for your users.\n\nWe can see this problem by changing\u00a0`views/noteview.hbs`\u00a0to use raw HTML output:\n\n```", "```js\\1\n\nFor better or for worse, the Notes application implements one security best practice\u2014all CSS and JavaScript files are loaded from the same server as the application. Therefore, for the most part, we can use the `'self'` policy. There are several exceptions:\n\n*   `scriptSrc`: Defines where we are allowed to load JavaScript. We do use inline JavaScript in\u00a0`noteview.hbs` and `index.hbs`, which must be allowed.\n*   `styleSrc`, `fontSrc`: We're loading CSS files from both the local server and from Google Fonts.\n*   `connectSrc`: The WebSockets channel used by Socket.IO is declared here.\n\nTo develop this, we can open the JavaScript console or Chrome DevTools while browsing the website. Errors will show up listing any domains of failed download attempts. Simply add such domains to the configuration object.\n\n### Making the ContentSecurityPolicy configurable\n\nObviously, the ContentSecurityPolicy settings shown here should be configurable. If nothing else the setting for `connectSrc` must be, because it can cause a problem that prevents Socket.IO from working. As shown here, the `connectSrc` setting includes the URL\u00a0`wss://notes.geekwisdom.net`. The `wss` protocol here refers to WebSockets and is designed to allow Socket.IO to work while Notes is hosted on `notes.geekwisdom.net`. But what about when we want to host it on a different domain?\n\nTo experiment with this problem, change the hard coded string to a different domain name then redeploy it to your server. In the JavaScript console in your browser you will get an error like this:\n\n```", "```js\\1\n\nThis lets us define an environment variable, `CSP_CONNECT_SRC_URL`, which will supply a URL to be added into the array passed to the `connectSrc` parameter. Otherwise, the `connectSrc` setting will be limited to `\"'self'\"`.\n\nThen in `compose-swarm/docker-compose.yml`, we can declare that variable like so:\n\n```", "```js\\1\n\nIn this case, we learned about preventing the browser from making premature DNS queries. The risk is that excess DNS queries give a false impression of which websites someone has visited.\n\nLet's next look at how to control which browser features can be enabled.\n\n## Using Helmet to control enabled browser features using the Feature-Policy header\n\nWeb browsers nowadays have a long list of features that can be enabled, such as vibrating a phone, or turning on the camera or microphone, or reading the accelerometer. These features are interesting and very useful in some cases, but can be\u00a0used maliciously. The Feature-Policy header lets us notify the web browser about which features to allow to be enabled, or to deny enabling.\n\nFor Notes we don't need any of those features, though some look intriguing as future possibilities. For instance, we could pivot to taking on Instagram if we allowed people to upload photos, maybe? In any case, this configuration is very strict:\n\n```", "```js\\1\n\nThis setting controls which domains are allowed to put this page into an `<iframe>`. Using `deny`, as shown here, prevents all sites from embedding this content using an\u00a0`<iframe>`. Using `sameorigin` allows the site to embed its own content. We can also list a single domain name to be allowed to embed this content.\n\nIn this section, you have learned about preventing our content from being embedded into another website using `<iframe>`.\n\nNow let's learn about hiding the fact that Notes is powered by Express.\n\n## Using Helmet to remove the X-Powered-By header\n\nThe `X-Powered-By` header can give malicious actors a clue about the software stack in use, informing them of attack algorithms that are likely to succeed. The\u00a0Hide Powered-By submodule for Helmet simply removes that header.\n\nExpress can disable this feature on its own:\n\n```", "```js\\1\n\nAnother option is to masquerade as some other stack like so:\n\n```", "```js\\1\n\nThis tells the browser to stick with the HTTPS version of the site for the next 60 days, and never visit the HTTP version.\n\nAnd, as long as we're on this issue, let's learn about\u00a0`express-force-ssl`, which is another way to implement a redirect so the users use HTTPS. After adding a dependency to that package in `package.json`, add this in `app.mjs`:\n\n```", "```js\\1\n\nThis causes an X-XSS-Protection header to be sent specifying\u00a0`1; mode=block`. This mode tells the browser to look for JavaScript in the request URL that also matches JavaScript on the page, and it then blocks that code. This is only one type of XSS attack, and therefore this is of limited usefulness. But it is still useful to have this enabled.\n\nIn this section, we've learned about using Helmet to enable a wide variety of security protections in web browsers. With these settings, our application can work with the browser to avoid a wide variety of attacks, and therefore make our site significantly safer.\n\nBut with this, we have exhausted what Helmet provides. In the next section, we'll learn about another package that prevents cross-site request forgery attacks.\n\n# Addressing Cross-Site Request Forgery (CSRF) attacks\n\nCSRF attacks are similar to XSS attacks in that both occur across multiple sites. In a CSRF attack, malicious software forges a bogus request on another site. To prevent such an attack, CSRF tokens are generated for each page view. The tokens are to be included as hidden values in HTML FORMs and then checked when the FORM is submitted. A mismatch on the tokens causes the request to be denied.\n\nThe `csurf` package is designed to be used with Express\u00a0[https://www.npmjs.com/package/csurf](https://www.npmjs.com/package/csurf)\u00a0. In the `notes` directory, run this:\n\n```", "```js\\1\n\nThe `csurf` middleware must be installed following the `cookieParser` middleware.\n\nNext, for every page that includes a FORM, we must generate and send a token with the page. That requires two things, in the `res.render` call we generate the token, sending the token with other data for the page, and then in the view template we include the token as a hidden INPUT on any form in the page. We're going to be touching on several files here, so let's get started.\n\nIn `routes/notes.mjs,` add the following as a parameter to the `res.render` call for the `/add`, `/edit`, `/view`, and `/destroy` routes:\n\n```", "```js\\1\n\nThis is a hidden INPUT, and whenever the FORM containing this is submitted this value will be carried along with the FORM parameters.\n\nThe result is that code on the server generates a token that is added to each FORM. By adding the token to FORMs, we ensure it is sent back to the server on FORM submission. Other software on the server can then match the received token to the tokens that have been sent. Any mismatched token will cause the request to be rejected.\n\nIn `views/login.hbs`, make the same addition but adding it inside the FORM like so:\n\n```", "```js\\1\n\nIn every case, we are adding a hidden INPUT field. These fields are not visible to the user and are therefore useful for carrying a wide variety of data that will be useful to receive on the server. We've already used hidden INPUT fields in Notes, such as in `noteedit.hbs` for the `docreate` flag.\n\nThis `<input>` tag renders the CSRF token into the FORM. When the FORM is submitted, the `csurf` middleware checks it for the correctness and rejects any that do not match.\n\nIn this section, we have learned how to stop an important type of attack, CSRF.\n\n# Denying SQL injection attacks\n\nSQL injection is another large class of security exploits, where the attacker puts SQL commands into input data. See\u00a0[https://www.xkcd.com/327/](https://www.xkcd.com/327/) for an example.\n\nThe best practice for avoiding this problem is to use parameterized database queries, allowing the database driver to prevent SQL injections simply by correctly encoding all SQL parameters. For example, we do this in the SQLite3 model:\n\n```", "```js\\1\n\nThe template strings feature of ES6 is very tempting to use everywhere. But it is not appropriate in all circumstances. In this case, the database query parameter would not be screened nor encoded, and if a miscreant can get a custom string to that query it could cause havoc in the database.\n\nIn this section, we learned about SQL injection attacks. We learned that the best defense against this sort of attack is the coding practice all coders should follow anyway, namely to use parameterized query methods offered by the database driver.\n\nIn the next section, we will learn about an effort in the Node.js community to screen packages for vulnerabilities.\n\n# Scanning for known vulnerabilities in Node.js packages\n\nBuilt-in to the npm command-line tool is a command, `npm audit`, for reporting known vulnerabilities in the dependencies of your application. To support this command is a team of people, and software, who scan packages added to the npm registry. Every third-party package used by your application is a potential security hole.\n\nIt's not just that a query against the application might trigger buggy code, whether in your code or third-party packages. In some cases, packages that explicitly cause harm have been added to the npm registry.\n\nTherefore the security audits of packages in the npm registry are extremely helpful to every Node.js developer.\n\nThe\u00a0`audit` command consults the vulnerability data collected by the auditing team and tells you about vulnerabilities in packages your application uses.\n\nWhen running `npm install`, the output might include a message like this:\n\n```", "```js\\1\n\nIn this case,\u00a0`minimist` is reported because `hbs` uses `handlebars`, which uses `optimist`, which uses `minimist`. There are six more instances where `minimist` is used by some package that's used by another package that our application is using.\n\nIn this case, we're given a recommendation, to upgrade to `hbs@4.1.1`, because that release results in depending on the correct version of `minimist`.\n\nIn another case, the chain of dependencies is this:\n\n```", "```js\\1\n\nTherefore it is our responsibility to fix this problem because it is in our code. The good news is that this particular package is not executed on the server side since jQuery is a client-side library that just so happens to be distributed through the npm repository.\n\nThe first step is to read the advisory to learn what the issue is. That way, we can evaluate for ourselves how serious this is, and what we must do to correctly fix the problem.\n\nWhat's not recommended is to blindly update to a later package release just because you're told to do so. What if the later release is incompatible with your application? The best practice is to test that the update does not break your code. You may need to develop tests that illustrate the vulnerability. That way, you can verify that updating the package dependency fixes the problem.\n\nIn this case, the advisory says that jQuery releases before 3.5.0 have an XSS vulnerability. We are using jQuery in Notes because it is required by Bootstrap, and on the day we read the Bootstrap documentation we were told to use a much earlier jQuery release. Today, the Bootstrap documentation says to use jQuery 3.5.1\\. That tells us the Bootstrap team has already tested against jQuery 3.5.1, and we are therefore safe to go ahead with updating the dependency.\n\nIn this section, we have learned about the security vulnerability report we can get from the npm command-line tool. Unfortunately for Yarn users, it appears that Yarn doesn't support this command. In any case, this is a valuable resource for being warned about known security issues.\n\nIn the next section, we'll learn about the best practices for cookie management in Express applications.\n\n# Using good cookie practices\n\nSome nutritionists say eating too many sweets, such as cookies, is bad for your health. Web cookies, however, are widely used for many purposes including recording whether a browser is logged in or not. One common use is for cookies to store session data to aid in knowing whether someone is logged in or not.\n\nIn the Notes application, we're already following the good practices described in the Express security guidelines:\n\n*   We're using an Express session cookie name different from the default shown in the documentation.\n*   The Express session cookie secret is not the default shown in the documentation.\n*   We use the `express-session` middleware, which only stores a session ID in the cookie, rather than the whole session data object.\n\nTaken together, an attacker can't exploit any known vulnerability that relies on the default values for these items. While it is convenient that many software products have default values, such as passwords, those defaults could be security vulnerabilities. For example, the default Raspberry Pi login/password is *pi*\u00a0and *raspberry*. While that's cute, any Raspbian-based IoT device that's left with the default login/password is susceptible to attack.\n\nBut there is more customization we can do to the cookie used with `express-session`. That\u00a0package has a few options available for improving security. See\u00a0[https://www.npmjs.com/package/express-session](https://www.npmjs.com/package/express-session), and then consider this change to the configuration:\n\n```", "```js\\1\n\nThis declares many specific network ports used for specific protocols. Each rule names the protocol in the\u00a0`description` attribute. The\u00a0`protocol` attribute says whether it is a UDP or TCP protocol. Remember that TCP is a stream-oriented protocol that ensures packets are delivered, and UDP, by contrast, is a packet-oriented protocol that does not ensure delivery. Each has characteristics making them suitable for different purposes.\n\nSomething missing is an\u00a0`ingress` rule for port `3306`, the MySQL port. That's because the `notes-public` server will not host a MySQL server based on the placement constraints.\n\nAnother thing to note is which rules allow traffic from public IP addresses, and which limit traffic to IP addresses inside the VPC. Many of these ports are used in support of the Docker swarm, and therefore do not need to communicate anywhere but other hosts on the VPC.\n\nAn issue to ponder is whether the SSH port should be left open to the entire internet. If you, or your team, only SSH into the VPC from a specific network, such as an office network, then this setting could list that network. And because the `cidr_blocks` attribute takes an array, it's possible to configure a list of networks, such as a company with several offices each with their own office network.\n\nIn `ec2-private.tf`, we must make a similar change to `ec2-private-sg`:\n\n```"]